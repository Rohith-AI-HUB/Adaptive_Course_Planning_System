# Adaptive Course Planning System Documentation (Q.md)

---

## 1. Project Overview
The **Adaptive Course Planning System** is an intelligent recommendation engine that suggests an optimal set of university courses for a student based on four numeric indicators:
- Previous GPA
- Attendance level
- Study effort (hours per week)
- Interest level

It combines three AI techniques:
1. **Fuzzy Logic** – classifies the student into *Strong*, *Average*, or *Weak*.
2. **Neural‑Network Grade Predictor** – a TensorFlow model that predicts the grade a student would obtain in a given subject.
3. **Particle Swarm Optimizer (PSO)** – searches the space of possible subject combinations (respecting a credit limit) to maximise the expected semester GPA while applying penalties for weak students on difficult courses.

The system can be accessed via a **Streamlit web UI** (`app.py`) or a **command‑line interface** (`main.py`).

---

## 2. Repository Structure & File‑by‑File Documentation
| Path | Purpose | Key Functions / Classes |
|------|---------|--------------------------|
| `README.md` | High‑level description, installation, quick‑start guide. | – |
| `app.py` | Streamlit UI that collects user inputs, runs fuzzy classification, PSO optimisation and displays results. | `st.slider`, `classify_student`, `run_pso` |
| `main.py` | CLI counterpart of `app.py`. Handles console input, runs the pipeline and prints results. | `classify_student`, `run_pso` |
| `generate_dataset.py` | Generates a synthetic training dataset (`data/student_performance.csv`). Includes a *subject affinity* feature (`subject_type` and `practical_skill`). | `clamp`, dataset generation loop |
| `nn/predictor.py` | Loads the pre‑trained Keras model (`model/grade_predictor.h5`) and a Min‑Max scaler built from the training CSV. Provides `predict_grade` which returns a grade in the range 0‑10. | `predict_grade`
| `nn/train_model.py` | Trains the neural‑network model on the synthetic dataset, saves the model, and prints MAE. | Model definition, training loop, `model.save` |
| `fuzzy/fuzzy_system.py` | Implements triangular membership functions and the fuzzy rule‑base that classifies a student. | `triangular`, `gpa_low/medium/high`, `attendance_*`, `study_*`, `classify_student` |
| `optimization/pso_scheduler.py` | Implements the PSO algorithm that searches for the best 4‑subject plan. Caches grade predictions to avoid redundant NN calls. | `run_pso`, `evaluate_plan`, `random_particle` |
| `data/subjects.csv` | CSV containing every available course (name, credits, difficulty, type, etc.). Used by the optimiser to translate indices to human‑readable subjects. |
| `data/student_performance.csv` | Synthetic training data generated by `generate_dataset.py`. Columns: `previous_gpa, attendance, study_hours, interest, difficulty, subject_type, final_grade`. |
| `model/grade_predictor.h5` | Pre‑trained TensorFlow model (see Section 5). |
| `tests/` | Simple sanity‑check scripts (`test_fuzzy.py`, `test_prediction.py`, `test_scheduler.py`). Can also be run with `pytest`. |

---

## 3. Development Methodology & Architectural Decisions
1. **Iterative Prototyping** – The project started with a minimal CLI that collected inputs and printed a static recommendation. Subsequent iterations added fuzzy classification, a neural‑network predictor, and finally the PSO optimiser.
2. **Separation of Concerns** – Each major concern lives in its own package:
   - `fuzzy/` for rule‑based reasoning.
   - `nn/` for data‑driven prediction.
   - `optimization/` for search/optimisation.
   - `app.py` and `main.py` act as thin orchestration layers.
3. **Data‑Driven Design** – All domain data (subjects, training rows) are stored as CSV files, making the system easy to extend without code changes.
4. **Caching** – Grade predictions are expensive (model inference). `pso_scheduler.py` caches results per `(student, subject)` tuple to keep the PSO runtime reasonable.
5. **Extensibility** – Adding new fuzzy rules, extra NN features, or alternative optimisation algorithms only requires adding new modules; the orchestration code remains unchanged.

---

## 4. Core Logic
### 4.1 Fuzzy Classification (`fuzzy/fuzzy_system.py`)
- Uses **triangular membership functions** for GPA, attendance, and study effort.
- Three linguistic categories: *Low*, *Medium*, *High*.
- Rule strengths are computed with `min` (AND) and `max` (OR) operators.
- Decision logic selects the strongest category (`Strong`, `Weak`, `Average`).

### 4.2 Grade Prediction (`nn/predictor.py`)
1. Load the Keras model (`grade_predictor.h5`).
2. Re‑build a `MinMaxScaler` from the original training CSV (`student_performance.csv`).
3. `predict_grade` builds a one‑row `DataFrame` with the same column order as the scaler, scales the features, runs `model.predict`, clamps the output to `[0,10]` and rounds to two decimals.

### 4.3 PSO Optimiser (`optimization/pso_scheduler.py`)
- **Particle representation**: a list of 4 distinct subject indices.
- **Fitness function** (`evaluate_plan`):
  - Compute total credits; penalise plans exceeding `MAX_CREDITS` (18) with a large negative score.
  - Average the predicted grades of the selected subjects.
  - If the student is *Weak*, subtract `0.7` for each *hard* subject (`difficulty > 7`).
- **Algorithm flow**:
  1. Initialise a swarm of random particles (`random_particle`).
  2. For a fixed number of `ITERATIONS` (30) evaluate each particle, keep the global best.
  3. Mutate particles towards the global best with a 50 % chance per particle, swapping one index with the best‑global index while avoiding duplicates.
- **Caching** (`grade_cache`) dramatically reduces repeated NN inference.

---

## 5. Machine‑Learning Model Specification
### 5.1 Architecture
```text
Input (6 features) → Dense(16, relu) → Dense(8, relu) → Dense(1, linear)
```
- **Features**: `previous_gpa, attendance, study_hours, interest, difficulty, subject_type`
- **Activation**: ReLU for hidden layers, linear output.
- **Loss**: Mean Squared Error (MSE)
- **Metric**: Mean Absolute Error (MAE)
- **Optimizer**: Adam, learning rate 0.01
- **Training epochs**: 100
- **Train‑test split**: 80 % / 20 % (random_state=42)

### 5.2 Hyper‑parameters
| Parameter | Value |
|-----------|-------|
| Hidden units (layer 1) | 16 |
| Hidden units (layer 2) | 8 |
| Learning rate | 0.01 |
| Batch size | default (full batch) |
| Epochs | 100 |
| Scaling | Min‑Max scaler fitted on all training columns except `final_grade` |

### 5.3 Training Data (`data/student_performance.csv`)
- **Rows**: 800 synthetic samples generated by `generate_dataset.py`.
- **Features**: `previous_gpa (4‑9.8)`, `attendance (3‑10)`, `study_hours (2‑10)`, `interest (1‑10)`, `difficulty (3‑10)`, `subject_type (0=theory,1=practical)`.
- **Target**: `final_grade` (0‑10) computed from a weighted sum of the inputs, a difficulty penalty, and an affinity bonus based on `subject_type` and a random `practical_skill`.
- **Pre‑processing**: No missing values; all numeric; scaled with `MinMaxScaler` before training.

### 5.4 Performance
- After training, the model reports a **Test MAE** (Mean Absolute Error) printed by `train_model.py`. In the provided repository the value is typically around **0.3‑0.4** grade points, indicating reasonable predictive power for the synthetic data.

---

## 6. Data Generation (`generate_dataset.py`)
- Generates 800 rows of synthetic student performance data.
- Introduces a **subject affinity** feature (`subject_type`) and a random `practical_skill` to simulate a student's preference for practical vs. theoretical subjects.
- Grade formula:
  ```text
  base = 0.35*GPA + 0.30*study + 0.20*attendance + 0.15*interest
  difficulty_penalty = difficulty * 0.08
  affinity_bonus = practical_skill * 0.15   (if practical) else (10‑practical_skill)*0.15
  grade = clamp(base - difficulty_penalty + affinity_bonus + noise)
  ```
- Writes a header row and all rows to `data/student_performance.csv`.

---

## 7. Testing
Three lightweight test scripts are provided under `tests/`:
- `test_fuzzy.py` – verifies fuzzy classification on sample inputs.
- `test_prediction.py` – loads the predictor and prints a grade for a synthetic feature vector.
- `test_scheduler.py` – runs the full pipeline (classification → PSO) and prints the recommended subjects and expected GPA.

Running `pytest tests/` will execute all three without additional dependencies.

---

## 8. Usage Guide
### 8.1 CLI
```bash
python main.py
```
Follow the prompts, then view the printed student type, recommended subjects, expected GPA and advice.

### 8.2 Web UI
```bash
streamlit run app.py
```
Open the displayed localhost URL, adjust the sliders, click **Generate Recommendation**, and view the results.

### 8.3 Re‑training the Model
If you modify `generate_dataset.py` or the underlying CSV, re‑train with:
```bash
python -m nn.train_model
```
The new model will overwrite `model/grade_predictor.h5`.

---

## 9. Extending the System
1. **Add new fuzzy rules** – edit `fuzzy/fuzzy_system.py` and adjust `classify_student`.
2. **Include extra NN features** – modify `generate_dataset.py` to output new columns, update `train_model.py` input shape, and adjust `predictor.py` feature construction.
3. **Swap optimiser** – implement a new algorithm in `optimization/` and replace the call in `app.py`/`main.py`.
4. **Persist cache** – replace the in‑memory `grade_cache` with a disk‑based cache for very large subject pools.

---

## 10. License
The project is released under the **MIT License** (see `LICENSE`).

---

*Documentation generated on 2026‑02‑17.*